#!/usr/bin/env python

import argparse
import subprocess
import tarfile
import json
import fileinput
import os
from datetime import datetime

remoteTraceFilesDir = "/var/tmp/remoteTraceFiles"

def getProcessesFromLogDir(logDir, robot, starttime, endtime):


    # Find trace files
    cmd = "ls -tr %s/trace_*" % logDir
    if starttime and endtime:
        cmd = "find %s -newermt '%s' ! -newermt '%s' -name 'trace_*' -print" % (logDir, starttime, endtime)
    if robot:
        cmd = 'ssh %s "ls -tr %s/trace_*"' % (robot, logDir)
        if starttime and endtime:
            cmd = 'ssh %s "find %s -newermt \'%s\' ! -newermt \'%s\' -name \'trace_*\' -print"' % (robot, logDir, starttime, endtime)
    logs = subprocess.check_output(cmd, shell=True).split("\n")

    # Remove empty string
    logs = logs[0:-1]

    # /var/tmp/falcons_control_20190623_145815/trace_A1_pp.json.slice1.tar.gz
    # Get process (trace_A1_pp) from the list
    processes = set()
    for log in logs:
        
        # As preprocessing step, remove any slice files that were compressed but not removed
        # This is possible when the software is killed at the moment the `tar` command was running
        # The `rm` command will then no longer be executed

        # trace_A1_pp.json.slice1 -> trace_A1_pp.json.slice
        if log[:-1].endswith(".slice"):
            # Remove this file
            cmd = "rm " + log
            if args.robot:
                cmd = 'ssh %s "rm %s"' % (args.robot, log)
            subprocess.call(cmd, shell=True)

        stripped_log = log.split("/")[-1].split(".")[0]
        processes.add(stripped_log)

    processes = list(processes)
    processes.sort()
    return processes

def getTraceObject(logDir, process, robot, starttime, endtime):

    # Get all files from this process
    cmd = "ls -1t %s/%s.json*" % (logDir, process)
    if starttime and endtime:
        cmd = "find %s -newermt '%s' ! -newermt '%s' -name '%s.json*' -print" % (logDir, starttime, endtime, process)
    if robot:
        cmd = 'ssh %s "ls -1t %s/%s.json*"' % (robot, logDir, process)
        if starttime and endtime:
            cmd = 'ssh %s "find %s -newermt \'%s\' ! -newermt \'%s\' -name \'%s.json*\' -print"' % (robot, logDir, starttime, endtime, process)
    logfiles = subprocess.check_output(cmd, shell=True).split("\n")

    # Remove empty string
    logfiles = logfiles[0:-1]

    # If the logfiles are located remotely on a robot, first download the files to a local folder
    if args.robot:

        # Delete folder contents if it exists, otherwise create folder
        if os.path.exists(remoteTraceFilesDir):
            cmd = "rm %s/*" % (remoteTraceFilesDir)
            subprocess.call(cmd, shell=True)
        else:
            os.mkdir(remoteTraceFilesDir)

        # Copy all remote trace files to local machine
        cmd = "scp %s:%s/%s.json* %s" % (args.robot, logDir, process, remoteTraceFilesDir)
        subprocess.call(cmd, shell=True)

        # Update logfiles to the copied files on the local machine
        cmd = "ls -1t %s/*" % (remoteTraceFilesDir)
        logfiles = subprocess.check_output(cmd, shell=True).split("\n")

        # Remove empty string
        logfiles = logfiles[0:-1]


    traceObj = {"traceEvents": []}

    # Read all JSON files
    for logfile in logfiles:
        content = ""
        if logfile.endswith(".tar.gz"):
            # Read file contents from tarfile
            with tarfile.open(logfile) as tfile:
                try:
                    for tfilemember in tfile.getmembers():
                        content = tfile.extractfile( tfilemember ).read()
                except IOError as e:
                    print "Error while parsing '%s': %s" % (logfile, str(e))
                    exit()

        else:
            # Read file contents from textfile
            with open(logfile, "r") as f:
                content = f.read()

                # If textfile, it was not closed properly, and the last entry may be corrupt:
                # 20729 {"cat":"cAbstractPathPlanning.cpp","pid":10300,"tid":-268437760,"ts":1561299237134432,"ph":"B","name":"cAbstractPathPlanning#iterateBlock","args":{"msg":""}},
                # 20730 {"cat":"/home/robocup/fal

                # Remove the last line (all chars after the last \n)
                lastidx = content.rfind("\n")
                content = content[0:lastidx-1] # '-1' to also remove the ',' from the previous line

                # Add characters to make it valid JSON
                content += "\n]}\n"

        try:
            # Parse content to JSON
            logFileAsJSON = json.loads(content)
        except ValueError as e:
            print "Error parsing JSON on '%s': %s" % (logfile, e)
            exit()

        # Add all JSON entries to traceObj
        traceObj["traceEvents"].extend( logFileAsJSON["traceEvents"] )

    # Sort traceObj entries by timestamp to enforce chronological order
    traceObj["traceEvents"].sort(key=lambda x: x["ts"])

    return traceObj

def traceObjectToHTML(traceObj):

    # Write traceObj to temporary trace file in /var/tmp/
    tmpTraceFile = "/var/tmp/tmptracefile"
    with open(tmpTraceFile, "wb") as f:
        json.dump(traceObj, f)

    # Convert JSON trace to HTML
    print "Converting trace to HTML..."
    cmd = "/home/robocup/falcons/data/external/catapult/tracing/bin/trace2html %s --output=%s.html" % (tmpTraceFile, tmpTraceFile)
    subprocess.call(cmd, shell=True)

    print "Done. Open with the following command:"
    print "google-chrome %s.html" % (tmpTraceFile)

def traceObjectToText(traceObj):

    # Write traceObj to temporary file in /var/tmp/
    tmpTraceFile = "/var/tmp/tmptracefile"
    print "Writing to", tmpTraceFile
    with open(tmpTraceFile, "wb") as f:

        for traceEntry in traceObj["traceEvents"]:

            # Skip "End" phase trace entries
            if traceEntry["ph"] == "E":
                continue

            # old format:
            # {"cat":"/home/robocup/falcons/code/packages/pathPlanning/src/adapters/cRTDBInputAdapter.cpp","pid":10300,"tid":362239936,"ts":1561299196996054,"ph":"B","name":"void cRTDBInputAdapter::getForbiddenAreas()","args":{"msg":""}},

            # Write with the following format:
            # timestamp filename:lineNr functionName threadID msg
            ts = datetime.fromtimestamp(float(traceEntry["ts"]) / 1000000.0)

            # lineNr is not known.
            try:
                if "msg" in traceEntry["args"].keys():
                    entryLine = "%s %s:0 %s %s %s\n" % (ts.strftime("%Y-%m-%d %H:%M:%S.%f"), traceEntry["cat"], traceEntry["name"], traceEntry["tid"], traceEntry["args"]["msg"])
                else:
                    entryLine = "%s %s:0 %s %s\n" % (ts.strftime("%Y-%m-%d %H:%M:%S.%f"), traceEntry["cat"], traceEntry["name"], traceEntry["tid"])
            except KeyError as e:
                print "Error: Expected key %s in '%s'" % (e, traceEntry)
                exit()
            f.write(entryLine)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='This Library finds the processes in a specific Logging directory. Given a Logging directory and process, all tracing slices are read from file. ')
    parser.add_argument('-t', '--text', action='store_true', help='generate textfile trace instead of the visual HTML page')
    group1 = parser.add_argument_group()
    group1.add_argument('-s', '--starttime', help='the starting timestamp of the tracing to open. Example: -s "2019-07-05 03:11:00"')
    group1.add_argument('-e', '--endtime', help='the ending timestamp of the tracing to open.  Example: -e "2019-07-05 03:20:00"')
    group2 = parser.add_mutually_exclusive_group()
    group2.add_argument('-d', '--directory', help='the directory to read the tracing from. Default: Choose a log dir')
    group2.add_argument('-r', '--robot', help='the robot to download the tracing from. Will let you choose which log dir to use. Example: -r r3')
    args = parser.parse_args()

    # TODO check date format if starttime and endtime are given

    if args.starttime and not args.endtime:
        print "Error: When giving a starttime, an endtime is also required"
        exit()
    if args.endtime and not args.starttime:
        print "Error: When giving an endtime, a starttime is also required"
        exit()

    # Determine falcons logging directory to use
    # If args.robot, get it from the robot
    # If args.directory, use the given directory
    if args.directory:
        newest_logdir = args.directory
    else:
        #cmd1 = subprocess.Popen('ls -1dt /var/tmp/falco*', shell=True, stdout=subprocess.PIPE)
        #if args.robot:
        #    cmd1 = subprocess.Popen('ssh %s "ls -1dt /var/tmp/falco*"' % (args.robot), stdout=subprocess.PIPE)
        #cmd2 = subprocess.Popen('head', shell=True, stdin=cmd1.stdout)
        #print cmd2.stdout
        #exit()
        #logdirs = cmd2.stdout.read()
        #print logdirs
        #exit()

        # The following commands give an error: ls: write error: Broken pipe
        # Because a | can not be used in subprocess.call(shell=True)
        # The alternative, using subprocess.Popen(), does not allow wildcards: *
        # We are able to use a | and a * by using ssh.
        #cmd = 'bash -c "head < <(ls -1dt /var/tmp/falco*)"'
        #cmd = 'ls -1dt /var/tmp/falco* | head'
        cmd = 'ssh localhost "ls -1dt /var/tmp/falco* | head"'
        if args.robot:
            cmd = 'ssh %s "ls -1dt /var/tmp/falco* | head"' % (args.robot)
        logdirs = subprocess.check_output(cmd, shell=True).split("\n")

        # Remove empty string
        logdirs = logdirs[0:-1]

        print "Choose a logging directory to view tracing:"
        idx = 0
        for logdir in logdirs:
            print "%s: %s" % (idx, logdir)
            idx += 1

        logdirIdx = raw_input("--> ")
        newest_logdir = logdirs[ int(logdirIdx) ]

    # Read the contents of the logging directory
    # If args.robot, read the contents on the robot using ssh
    processes = getProcessesFromLogDir(newest_logdir, args.robot, args.starttime, args.endtime)
    print "Choose a process to view tracing (or more separated by commas: e.g. '2,3,4'):"
    idx = 0
    for process in processes:
        print "%s: %s" % (idx, process)
        idx += 1

    processIdx = raw_input("--> ")

    if "," in processIdx:
        # Remove spaces
        processIdx = processIdx.replace(" ", "")

        indexes = processIdx.split(",")
        traceObjMerged = {"traceEvents": []}

        for idx in indexes:
            idx = int(idx)
            print "Reading all Trace files for", processes[idx], "..."
            traceObj = getTraceObject(newest_logdir, processes[idx], args.robot, args.starttime, args.endtime)
            traceObjMerged["traceEvents"].extend( traceObj["traceEvents"] )

        # Sort traceObj entries by timestamp to enforce chronological order
        traceObjMerged["traceEvents"].sort(key=lambda x: x["ts"])


        if args.text:
            traceObjectToText(traceObjMerged)
        else:
            traceObjectToHTML(traceObjMerged)

    else:

        processIdx = int(processIdx)
        print "Reading all Trace files for", processes[processIdx], "..."
        traceObj = getTraceObject(newest_logdir, processes[processIdx], args.robot, args.starttime, args.endtime)

        if args.text:
            traceObjectToText(traceObj)
        else:
            traceObjectToHTML(traceObj)
